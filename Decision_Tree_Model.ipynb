{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree Model",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXNVudlEUWxf232px0e3ft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/derek-byte/Sololearn-Machine-Learning/blob/main/Decision_Tree_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lesson 30.1: How to Build a Decision Tree"
      ],
      "metadata": {
        "id": "YwNYcJPDkD9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision trees are slow to develop but fast to compute. Decision trees are used to explain predictions to customers because it is a series of yes or nos. "
      ],
      "metadata": {
        "id": "EhVQy6VTN-Co"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0heD2b_j_6S"
      },
      "outputs": [],
      "source": [
        "# Gini impurity is a measure of how pure a set is. We’ll later see how we can use the gini impurity to calculate the information gain. \n",
        "# If gini is closer to 50% is best\n",
        "gini = 2 * p * (1 - p)\n",
        "\n",
        "# Left side check\n",
        "# Percent of passengers who survived = 197/(197+328) = 0.3752\n",
        "# Percent of passengers who didn’t survive = 1 - 0.375 = 0.6248\n",
        "ans = 2 * 0.3752 * 0.6248 = 0.4689\n",
        "\n",
        "# Right side check\n",
        "ans = 2 * 145/(145+217) * 217/(145+217) = 0.4802\n",
        "\n",
        "# Entropy is another measure of purity. It will be a value between 0 and 1 where 1 is completely impure (50% survived and 50% didn’t survive) and 0 is completely pure (100% the same class).\n",
        "# If entropy is closer to 50% is best\n",
        "entropy = -(p * log(p) + (1-p) * log(1-p))\n",
        "\n",
        "# On the left (Age<=30):\n",
        "# Left: Survived, not-survived: 197, 328\n",
        "# Right: 145, 217\n",
        "\n",
        "p = 197/(197+328) = 0.3752\n",
        "Entropy = -(0.375 * log(0.375) + (1-0.375) * log(1-0.375)) = 0.9546\n",
        "\n",
        "# Information Gain\n",
        "Gini = 2 * 342/887 * 545/887 = 0.4738\n",
        "# Left \n",
        "Information gain = 0.4738 - 525/887 * 0.4689 - 362/887 * 0.4802 = 0.0003\n",
        "#Right\n",
        "Information gain = 0.4738 - 314/887 * 0.3828 - 573/887 * 0.3081 = 0.1393"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lesson 32.1: Decision Tree (Scikit-Learn)"
      ],
      "metadata": {
        "id": "Ltrlns3FDcOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
        "df['male'] = df['Sex'] == 'male'\n",
        "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
        "y = df['Survived'].values\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=22)\n",
        "model.fit(X_train, y_train)\n",
        "print(model.predict([[3, True, 22, 1, 0, 7.25]]))"
      ],
      "metadata": {
        "id": "IjuXYzXNaHTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "from IPython.display import Image\n",
        "\n",
        "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
        "\n",
        "feature_names = ['Pclass']\n",
        "X = df[feature_names].values\n",
        "y = df['Survived'].values\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X, y)\n",
        "\n",
        "dot_file = export_graphviz(dt, feature_names=feature_names)\n",
        "graph = graphviz.Source(dot_file)\n",
        "graph.render(filename='tree', format='png', cleanup=True)"
      ],
      "metadata": {
        "id": "-aALn2ap5IF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lesson 34.1: Pruning Decision Trees (Scikit-learn)"
      ],
      "metadata": {
        "id": "nTViEolu_O8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepruning Technique 1: Limiting the depth\n",
        "# Prepruning Technique 2: Avoiding leaves with few datapoints\n",
        "# Prepruning Technique 3: Limiting the number of leaf nodes\n",
        "\n",
        "# Decision tree with, max depth of 3, minimum samples per leaf of 2, maximum number of leaf nodes of 10\n",
        "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=2, max_leaf_nodes=10)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [5, 15, 25],\n",
        "    'min_samples_leaf': [1, 3],\n",
        "    'max_leaf_nodes': [10, 20, 35, 50]}\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "gs = GridSearchCV(dt, param_grid, scoring='f1', cv=5)\n",
        "\n",
        "gs.fit(X, y)\n",
        "\n",
        "print(gs.best_score)"
      ],
      "metadata": {
        "id": "IryGHhqb_VQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project: Split to Achieve Gain"
      ],
      "metadata": {
        "id": "qrmZE9ujSJBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S = [int(x) for x in input().split()]\n",
        "A = [int(x) for x in input().split()]\n",
        "B = [int(x) for x in input().split()]\n",
        "\n",
        "total_len = len(A) + len(B)\n",
        "\n",
        "i = 0\n",
        "for num in S:\n",
        "    if num == 1:\n",
        "        i += 1\n",
        "j = 0\n",
        "for num in A:\n",
        "    if num == 1:\n",
        "        j += 1 \n",
        "k = 0\n",
        "for num in B:\n",
        "    if num == 1:\n",
        "        k += 1 \n",
        "\n",
        "gini = 2 * (i/len(S)) * (1 - (i/len(S)))\n",
        "\n",
        "left_set = 2 * (j/len(A)) * (1 - j/len(A))\n",
        "right_set = 2 * (k/len(B)) * (1 - k/len(B))\n",
        "\n",
        "information = gini - (len(A)/len(S) * left_set) - (len(B)/len(S) * right_set)\n",
        "\n",
        "print(round(information, 5))"
      ],
      "metadata": {
        "id": "b2OeEMs1SN7i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}